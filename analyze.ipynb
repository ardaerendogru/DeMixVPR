{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.helper import GetModel\n",
    "from dataloaders.train_loader import GSVCitiesDataset\n",
    "from dataloaders.test_loader import TestDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import os\n",
    "from pytorch_metric_learning import losses, miners\n",
    "from train import train_model\n",
    "from evaluation import eval_model\n",
    "from utils.lr_scheduler import custom_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "train_dataset = GSVCitiesDataset(generated_data_prob=0)\n",
    "test_dataset = TestDataset()\n",
    "\n",
    "num_workers = 16\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=100, \n",
    "                              shuffle=True, \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True\n",
    "                              )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             batch_size=100, \n",
    "                             shuffle=False, \n",
    "                             num_workers=num_workers, \n",
    "                             pin_memory=True\n",
    "                             )\n",
    "sf_xs_test_dataset = TestDataset(path='./data/sf_xs/test')\n",
    "sf_xs_test_dataloader = DataLoader(sf_xs_test_dataset, \n",
    "                             batch_size=100, \n",
    "                             shuffle=False, \n",
    "                             num_workers=num_workers, \n",
    "                             pin_memory=True\n",
    "                             )\n",
    "tokyo_test_dataset = TestDataset(path='./data/tokyo_xs/test')\n",
    "tokyo_test_dataloader = DataLoader(tokyo_test_dataset, \n",
    "                             batch_size=100, \n",
    "                             shuffle=False, \n",
    "                             num_workers=num_workers, \n",
    "                             pin_memory=True\n",
    "                             )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "EXPERIMENT_NAME = 'Adam_1e4_1e5_custom'\n",
    "\n",
    "model = GetModel(aggregator='gem')\n",
    "model = model.to('cuda')\n",
    "if TRAIN:   \n",
    "    miner = miners.BatchHardMiner()\n",
    "    loss_fn = losses.ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                            lr=1e-4,  \n",
    "                            weight_decay=1e-5)\n",
    "    train_args = {\n",
    "        'model': model,\n",
    "        'loss_fn': loss_fn,\n",
    "        'miner': miner,\n",
    "        'optimizer': optimizer,\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "        'test_dataset': test_dataset,\n",
    "        'num_epochs': 45,\n",
    "        'overfitting_detector': True,\n",
    "        'verbose': True,\n",
    "        'scheduler': 'custom',\n",
    "        'job_name': EXPERIMENT_NAME\n",
    "    }\n",
    "\n",
    "if TRAIN:\n",
    "    model, r1, r5 = train_model(**train_args)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'./weights/{EXPERIMENT_NAME}.pth'))\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "print('Evaluating on test sets')\n",
    "print('-'*20)\n",
    "sf_xs_val_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'test_dataset': test_dataset,\n",
    "    'verbose': True,\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_val_args)\n",
    "\n",
    "sf_xs_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': sf_xs_test_dataloader,\n",
    "    'test_dataset': sf_xs_test_dataset,\n",
    "    'verbose': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_test_args)\n",
    "\n",
    "\n",
    "tokyo_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': tokyo_test_dataloader,\n",
    "    'test_dataset': tokyo_test_dataset,\n",
    "    'verbose': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**tokyo_test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MixVPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "EXPERIMENT_NAME = 'Adam_1e4_1e5_mixvpr_custom'\n",
    "\n",
    "model = GetModel(aggregator='mixvpr', input_size=256, output_size=512)\n",
    "model = model.to('cuda')\n",
    "if TRAIN:   \n",
    "    miner = miners.BatchHardMiner()\n",
    "    loss_fn = losses.ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                            lr=1e-4,  \n",
    "                            weight_decay=1e-5)\n",
    "    train_args = {\n",
    "        'model': model,\n",
    "        'loss_fn': loss_fn,\n",
    "        'miner': miner,\n",
    "        'optimizer': optimizer,\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "        'test_dataset': test_dataset,\n",
    "        'num_epochs': 45,\n",
    "        'overfitting_detector': True,\n",
    "        'patience': 45,\n",
    "        'verbose': True,\n",
    "        'scheduler': 'custom',\n",
    "        'job_name': EXPERIMENT_NAME\n",
    "    }\n",
    "\n",
    "if TRAIN:\n",
    "    model, r1, r5 = train_model(**train_args)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'./weights/{EXPERIMENT_NAME}.pth'))\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "print('Evaluating on test sets')\n",
    "print('-'*20)\n",
    "sf_xs_val_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'test_dataset': test_dataset,\n",
    "    'verbose': True,\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_val_args)\n",
    "\n",
    "sf_xs_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': sf_xs_test_dataloader,\n",
    "    'test_dataset': sf_xs_test_dataset,\n",
    "    'verbose': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_test_args)\n",
    "\n",
    "\n",
    "tokyo_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': tokyo_test_dataloader,\n",
    "    'test_dataset': tokyo_test_dataset,\n",
    "    'verbose': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**tokyo_test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.helper import GetModel, GetMultiModel, GetDeAttNet\n",
    "from dataloaders.train_loader import GSVCitiesDataset\n",
    "from dataloaders.test_loader import TestDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import os\n",
    "from pytorch_metric_learning import losses, miners\n",
    "from train import train_model\n",
    "from evaluation import eval_model\n",
    "from utils.lr_scheduler import custom_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "train_dataset = GSVCitiesDataset(generated_data_prob=0, multi_model=True)\n",
    "test_dataset = TestDataset(multi_model=True)\n",
    "\n",
    "num_workers = 16\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=100, \n",
    "                              shuffle=True, \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True\n",
    "                              )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             batch_size=100, \n",
    "                             shuffle=False, \n",
    "                             num_workers=num_workers, \n",
    "                             pin_memory=True\n",
    "                             )\n",
    "sf_xs_test_dataset = TestDataset(path='./data/sf_xs/test', multi_model=True)\n",
    "sf_xs_test_dataloader = DataLoader(sf_xs_test_dataset, \n",
    "                             batch_size=100, \n",
    "                             shuffle=False, \n",
    "                             num_workers=num_workers, \n",
    "                             pin_memory=True\n",
    "                             )\n",
    "tokyo_test_dataset = TestDataset(path='./data/tokyo_xs/test', multi_model=True)\n",
    "tokyo_test_dataloader = DataLoader(tokyo_test_dataset, \n",
    "                             batch_size=100, \n",
    "                             shuffle=False, \n",
    "                             num_workers=num_workers, \n",
    "                             pin_memory=True\n",
    "                             )\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPTH MIXVPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "EXPERIMENT_NAME = 'multimodel_depth_mixvpr_arda_512'\n",
    "\n",
    "model = GetMultiModel(aggregator='mixvpr', use_fusion=False, input_size=512, output_size=512)\n",
    "model = model.to('cuda')\n",
    "# model.load_state_dict(torch.load(f'./weights/{EXPERIMENT_NAME}.pth'))\n",
    "\n",
    "if TRAIN:   \n",
    "    miner = miners.BatchHardMiner()\n",
    "    loss_fn = losses.ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                            lr=1e-4,  \n",
    "                            weight_decay=1e-5)\n",
    "    train_args = {\n",
    "        'model': model,\n",
    "        'loss_fn': loss_fn,\n",
    "        'miner': miner,\n",
    "        'optimizer': optimizer,\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "        'test_dataset': test_dataset,\n",
    "        'num_epochs': 45,\n",
    "        'patience': 45,\n",
    "        'overfitting_detector': True,\n",
    "        'verbose': True,\n",
    "        'scheduler': 'custom',\n",
    "        'job_name': EXPERIMENT_NAME,\n",
    "        'multi_model': True\n",
    "    }\n",
    "\n",
    "if TRAIN:\n",
    "    model, r1, r5 = train_model(**train_args)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'./weights/{EXPERIMENT_NAME}.pth'))\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "print('Evaluating on test sets')\n",
    "print('-'*20)\n",
    "sf_xs_val_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'test_dataset': test_dataset,\n",
    "    'verbose': True,\n",
    "    'multi_model': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_val_args)\n",
    "\n",
    "sf_xs_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': sf_xs_test_dataloader,\n",
    "    'test_dataset': sf_xs_test_dataset,\n",
    "    'verbose': True,\n",
    "    'multi_model': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_test_args)\n",
    "\n",
    "\n",
    "tokyo_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': tokyo_test_dataloader,\n",
    "    'test_dataset': tokyo_test_dataset,\n",
    "    'verbose': True,\n",
    "    'multi_model': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**tokyo_test_args)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeAttNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "EXPERIMENT_NAME = 'multimodel_deattnet'\n",
    "\n",
    "model = GetDeAttNet(aggregator='gem')\n",
    "model = model.to('cuda')\n",
    "# model.load_state_dict(torch.load(f'./weights/{EXPERIMENT_NAME}.pth'))\n",
    "\n",
    "if TRAIN:   \n",
    "    miner = miners.BatchHardMiner()\n",
    "    loss_fn = losses.ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                            lr=1e-4,  \n",
    "                            weight_decay=1e-5)\n",
    "    train_args = {\n",
    "        'model': model,\n",
    "        'loss_fn': loss_fn,\n",
    "        'miner': miner,\n",
    "        'optimizer': optimizer,\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "        'test_dataset': test_dataset,\n",
    "        'num_epochs': 45,\n",
    "        'patience': 45,\n",
    "        'overfitting_detector': True,\n",
    "        'verbose': True,\n",
    "        'scheduler': 'custom',\n",
    "        'job_name': EXPERIMENT_NAME,\n",
    "        'multi_model': True\n",
    "    }\n",
    "\n",
    "if TRAIN:\n",
    "    model, r1, r5 = train_model(**train_args)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'./weights/{EXPERIMENT_NAME}.pth'))\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "print('Evaluating on test sets')\n",
    "print('-'*20)\n",
    "sf_xs_val_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'test_dataset': test_dataset,\n",
    "    'verbose': True,\n",
    "    'multi_model': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_val_args)\n",
    "\n",
    "sf_xs_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': sf_xs_test_dataloader,\n",
    "    'test_dataset': sf_xs_test_dataset,\n",
    "    'verbose': True,\n",
    "    'multi_model': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**sf_xs_test_args)\n",
    "\n",
    "\n",
    "tokyo_test_args = {\n",
    "    'model': model,\n",
    "    'test_dataloader': tokyo_test_dataloader,\n",
    "    'test_dataset': tokyo_test_dataset,\n",
    "    'verbose': True,\n",
    "    'multi_model': True\n",
    "}\n",
    "queries, database, predictions = eval_model(**tokyo_test_args)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
